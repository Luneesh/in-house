{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as an\n",
    "import scanpy as sc\n",
    "import scarches as sca\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_printoptions(precision=3, sci_mode=False, edgeitems=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luna/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/anndata/compat/__init__.py:358: FutureWarning: Moving element from .uns['neighbors']['distances'] to .obsp['distances'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "hips = an.read_h5ad(\"data/hiPSC.h5ad\")\n",
    "#tips = an.read_h5ad(\"\")\n",
    "#hips = tips  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 3103230 stored elements and shape (4694, 1968)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in hips.obs.columns:\n",
    "    if hips.obs[col].dtype == np.float32:\n",
    "        hips.obs[col] = hips.obs[col].astype(np.int64)\n",
    "    if hips.obs[col].dtype == np.int32:\n",
    "        hips.obs[col] = hips.obs[col].astype(np.int64)\n",
    "hips.X.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "for i in hips.obs:\n",
    "    print(type(hips.obs[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hips.Y=hips.obsp[\"distances\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca.utils.add_annotations(hips,\"scripts/reactome.gmt\", min_genes=12, clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hips._inplace_subset_var(hips.varm[\"I\"].sum(1)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(hips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig.ident</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>run</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>percent.mt</th>\n",
       "      <th>percent.dissoc</th>\n",
       "      <th>RNA_snn_res.0.3</th>\n",
       "      <th>seurat_clusters</th>\n",
       "      <th>RNA_snn_res.0.22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>batch_2_A_AAACCCAAGGTAATCA-1</th>\n",
       "      <td>SeuratProject</td>\n",
       "      <td>48806.0</td>\n",
       "      <td>6892.0</td>\n",
       "      <td>0h_A</td>\n",
       "      <td>iPSC_99_4</td>\n",
       "      <td>5.110027</td>\n",
       "      <td>0.013308</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_2_A_AAAGGATCATCCAATG-1</th>\n",
       "      <td>SeuratProject</td>\n",
       "      <td>5460.0</td>\n",
       "      <td>2307.0</td>\n",
       "      <td>0h_A</td>\n",
       "      <td>iPSC_99_4</td>\n",
       "      <td>0.201465</td>\n",
       "      <td>0.015073</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_2_A_AAAGGATGTGGTCAAG-1</th>\n",
       "      <td>SeuratProject</td>\n",
       "      <td>32899.0</td>\n",
       "      <td>5707.0</td>\n",
       "      <td>0h_A</td>\n",
       "      <td>iPSC_99_4</td>\n",
       "      <td>4.097389</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_2_A_AAAGGTAGTGTCATCA-1</th>\n",
       "      <td>SeuratProject</td>\n",
       "      <td>37327.0</td>\n",
       "      <td>6069.0</td>\n",
       "      <td>0h_A</td>\n",
       "      <td>iPSC_99_4</td>\n",
       "      <td>4.532912</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_2_A_AAATGGACATATCTGG-1</th>\n",
       "      <td>SeuratProject</td>\n",
       "      <td>18633.0</td>\n",
       "      <td>4701.0</td>\n",
       "      <td>0h_A</td>\n",
       "      <td>iPSC_99_4</td>\n",
       "      <td>4.932110</td>\n",
       "      <td>0.013176</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_1_sample_120H_TTTACTGCATCCGCGA-1</th>\n",
       "      <td>SeuratProject</td>\n",
       "      <td>14013.0</td>\n",
       "      <td>4629.0</td>\n",
       "      <td>120h</td>\n",
       "      <td>iPSC_72_1</td>\n",
       "      <td>4.767002</td>\n",
       "      <td>0.017398</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_1_sample_120H_TTTCACATCAGCCCAG-1</th>\n",
       "      <td>SeuratProject</td>\n",
       "      <td>21173.0</td>\n",
       "      <td>5140.0</td>\n",
       "      <td>120h</td>\n",
       "      <td>iPSC_72_1</td>\n",
       "      <td>4.127899</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_1_sample_120H_TTTCAGTAGTACAGAT-1</th>\n",
       "      <td>SeuratProject</td>\n",
       "      <td>22107.0</td>\n",
       "      <td>5437.0</td>\n",
       "      <td>120h</td>\n",
       "      <td>iPSC_72_1</td>\n",
       "      <td>2.035554</td>\n",
       "      <td>0.013721</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_1_sample_120H_TTTGATCAGCTCCATA-1</th>\n",
       "      <td>SeuratProject</td>\n",
       "      <td>12806.0</td>\n",
       "      <td>4127.0</td>\n",
       "      <td>120h</td>\n",
       "      <td>iPSC_72_1</td>\n",
       "      <td>3.428081</td>\n",
       "      <td>0.015297</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_1_sample_120H_TTTGTTGAGTTGGCGA-1</th>\n",
       "      <td>SeuratProject</td>\n",
       "      <td>32140.0</td>\n",
       "      <td>5614.0</td>\n",
       "      <td>120h</td>\n",
       "      <td>iPSC_72_1</td>\n",
       "      <td>2.722464</td>\n",
       "      <td>0.013653</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4694 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           orig.ident  nCount_RNA  \\\n",
       "batch_2_A_AAACCCAAGGTAATCA-1            SeuratProject     48806.0   \n",
       "batch_2_A_AAAGGATCATCCAATG-1            SeuratProject      5460.0   \n",
       "batch_2_A_AAAGGATGTGGTCAAG-1            SeuratProject     32899.0   \n",
       "batch_2_A_AAAGGTAGTGTCATCA-1            SeuratProject     37327.0   \n",
       "batch_2_A_AAATGGACATATCTGG-1            SeuratProject     18633.0   \n",
       "...                                               ...         ...   \n",
       "batch_1_sample_120H_TTTACTGCATCCGCGA-1  SeuratProject     14013.0   \n",
       "batch_1_sample_120H_TTTCACATCAGCCCAG-1  SeuratProject     21173.0   \n",
       "batch_1_sample_120H_TTTCAGTAGTACAGAT-1  SeuratProject     22107.0   \n",
       "batch_1_sample_120H_TTTGATCAGCTCCATA-1  SeuratProject     12806.0   \n",
       "batch_1_sample_120H_TTTGTTGAGTTGGCGA-1  SeuratProject     32140.0   \n",
       "\n",
       "                                        nFeature_RNA   run sample_name  \\\n",
       "batch_2_A_AAACCCAAGGTAATCA-1                  6892.0  0h_A   iPSC_99_4   \n",
       "batch_2_A_AAAGGATCATCCAATG-1                  2307.0  0h_A   iPSC_99_4   \n",
       "batch_2_A_AAAGGATGTGGTCAAG-1                  5707.0  0h_A   iPSC_99_4   \n",
       "batch_2_A_AAAGGTAGTGTCATCA-1                  6069.0  0h_A   iPSC_99_4   \n",
       "batch_2_A_AAATGGACATATCTGG-1                  4701.0  0h_A   iPSC_99_4   \n",
       "...                                              ...   ...         ...   \n",
       "batch_1_sample_120H_TTTACTGCATCCGCGA-1        4629.0  120h   iPSC_72_1   \n",
       "batch_1_sample_120H_TTTCACATCAGCCCAG-1        5140.0  120h   iPSC_72_1   \n",
       "batch_1_sample_120H_TTTCAGTAGTACAGAT-1        5437.0  120h   iPSC_72_1   \n",
       "batch_1_sample_120H_TTTGATCAGCTCCATA-1        4127.0  120h   iPSC_72_1   \n",
       "batch_1_sample_120H_TTTGTTGAGTTGGCGA-1        5614.0  120h   iPSC_72_1   \n",
       "\n",
       "                                        percent.mt  percent.dissoc  \\\n",
       "batch_2_A_AAACCCAAGGTAATCA-1              5.110027        0.013308   \n",
       "batch_2_A_AAAGGATCATCCAATG-1              0.201465        0.015073   \n",
       "batch_2_A_AAAGGATGTGGTCAAG-1              4.097389        0.014101   \n",
       "batch_2_A_AAAGGTAGTGTCATCA-1              4.532912        0.013420   \n",
       "batch_2_A_AAATGGACATATCTGG-1              4.932110        0.013176   \n",
       "...                                            ...             ...   \n",
       "batch_1_sample_120H_TTTACTGCATCCGCGA-1    4.767002        0.017398   \n",
       "batch_1_sample_120H_TTTCACATCAGCCCAG-1    4.127899        0.014142   \n",
       "batch_1_sample_120H_TTTCAGTAGTACAGAT-1    2.035554        0.013721   \n",
       "batch_1_sample_120H_TTTGATCAGCTCCATA-1    3.428081        0.015297   \n",
       "batch_1_sample_120H_TTTGTTGAGTTGGCGA-1    2.722464        0.013653   \n",
       "\n",
       "                                       RNA_snn_res.0.3 seurat_clusters  \\\n",
       "batch_2_A_AAACCCAAGGTAATCA-1                         2               0   \n",
       "batch_2_A_AAAGGATCATCCAATG-1                         7               0   \n",
       "batch_2_A_AAAGGATGTGGTCAAG-1                         2               0   \n",
       "batch_2_A_AAAGGTAGTGTCATCA-1                         2               0   \n",
       "batch_2_A_AAATGGACATATCTGG-1                         2               0   \n",
       "...                                                ...             ...   \n",
       "batch_1_sample_120H_TTTACTGCATCCGCGA-1               3               2   \n",
       "batch_1_sample_120H_TTTCACATCAGCCCAG-1               5               4   \n",
       "batch_1_sample_120H_TTTCAGTAGTACAGAT-1               3               2   \n",
       "batch_1_sample_120H_TTTGATCAGCTCCATA-1               3               2   \n",
       "batch_1_sample_120H_TTTGTTGAGTTGGCGA-1               3               2   \n",
       "\n",
       "                                        RNA_snn_res.0.22  \n",
       "batch_2_A_AAACCCAAGGTAATCA-1                         0.0  \n",
       "batch_2_A_AAAGGATCATCCAATG-1                         0.0  \n",
       "batch_2_A_AAAGGATGTGGTCAAG-1                         0.0  \n",
       "batch_2_A_AAAGGTAGTGTCATCA-1                         0.0  \n",
       "batch_2_A_AAATGGACATATCTGG-1                         0.0  \n",
       "...                                                  ...  \n",
       "batch_1_sample_120H_TTTACTGCATCCGCGA-1               2.0  \n",
       "batch_1_sample_120H_TTTCACATCAGCCCAG-1               4.0  \n",
       "batch_1_sample_120H_TTTCAGTAGTACAGAT-1               2.0  \n",
       "batch_1_sample_120H_TTTGATCAGCTCCATA-1               2.0  \n",
       "batch_1_sample_120H_TTTGTTGAGTTGGCGA-1               2.0  \n",
       "\n",
       "[4694 rows x 10 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.pp.log1p(hips)\n",
    "hips.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(\n",
    "    hips,\n",
    "    n_top_genes=2000,\n",
    "    batch_key=\"sample_name\",\n",
    "    subset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_terms = hips.varm[\"I\"].sum(0)>12\n",
    "hips.uns['terms'] = np.array(hips.uns['terms'])[select_terms].tolist()\n",
    "hips.varm['I'] = hips.varm['I'][:, select_terms]\n",
    "hips._inplace_subset_var(hips.varm['I'].sum(1)>0)\n",
    "#hips.Y = hips.obsp[\"distances\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 4694 Ã— 1968\n",
       "    obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'run', 'sample_name', 'percent.mt', 'percent.dissoc', 'RNA_snn_res.0.3', 'seurat_clusters', 'RNA_snn_res.0.22'\n",
       "    var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n",
       "    uns: 'neighbors', 'terms', 'log1p', 'hvg'\n",
       "    obsm: 'X_mnn', 'X_umap'\n",
       "    varm: 'I'\n",
       "    obsp: 'distances'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SeuratProject', 'SeuratProject', 'SeuratProject', 'SeuratProject', 'SeuratProject', ..., 'SeuratProject', 'SeuratProject', 'SeuratProject', 'SeuratProject', 'SeuratProject']\n",
      "Length: 4694\n",
      "Categories (1, object): ['SeuratProject']\n",
      "[48806.  5460. 32899. 37327. 18633. 24022. 38150. ... 11334. 10288. 14013.\n",
      " 21173. 22107. 12806. 32140.]\n",
      "[6892. 2307. 5707. 6069. 4701. 5670. 6478. ... 4117. 3380. 4629. 5140.\n",
      " 5437. 4127. 5614.]\n",
      "['0h_A', '0h_A', '0h_A', '0h_A', '0h_A', ..., '120h', '120h', '120h', '120h', '120h']\n",
      "Length: 4694\n",
      "Categories (4, object): ['0h_A', '0h_B', '48h', '120h']\n",
      "['iPSC_99_4', 'iPSC_99_4', 'iPSC_99_4', 'iPSC_99_4', 'iPSC_99_4', ..., 'iPSC_72_1', 'iPSC_72_1', 'iPSC_72_1', 'iPSC_72_1', 'iPSC_72_1']\n",
      "Length: 4694\n",
      "Categories (4, object): ['iPSC_20_6_4', 'iPSC_54_3', 'iPSC_72_1', 'iPSC_99_4']\n",
      "[5.11 0.2  4.1  4.53 4.93 6.64 6.03 ... 7.36 3.35 4.77 4.13 2.04 3.43 2.72]\n",
      "[0.01 0.02 0.01 0.01 0.01 0.01 0.01 ... 0.02 0.02 0.02 0.01 0.01 0.02 0.01]\n",
      "['2', '7', '2', '2', '2', ..., '3', '5', '3', '3', '3']\n",
      "Length: 4694\n",
      "Categories (9, object): ['0', '1', '2', '3', ..., '5', '6', '7', '8']\n",
      "['0', '0', '0', '0', '0', ..., '2', '4', '2', '2', '2']\n",
      "Length: 4694\n",
      "Categories (6, object): ['0', '1', '2', '3', '4', '5']\n",
      "[0. 0. 0. 0. 0. 0. 0. ... 2. 2. 2. 4. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "for i in hips.obs:\n",
    "    print(hips.obs[i].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INITIALIZING NEW NETWORK..............\n",
      "Encoder Architecture:\n",
      "\tInput Layer in, out and cond: 1968 256 4\n",
      "\tHidden Layer 1 in/out: 256 64\n",
      "\tMean/Var Layer in/out: 64 10\n",
      "Decoder Architecture:\n",
      "\tFirst Layer in, out and cond:  10 64 4\n",
      "\tHidden Layer 1 in/out: 64 256\n",
      "\tOutput Layer in/out:  256 1968 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "intr_cvae = sca.models.TRVAE(\n",
    "    adata=hips,\n",
    "    condition_key='sample_name',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_kwargs = {\n",
    "    \"early_stopping_metric\": \"val_unweighted_loss\",\n",
    "    \"threshold\": 0,\n",
    "    \"patience\": 50,\n",
    "    \"reduce_lr\": True,\n",
    "    \"lr_patience\": 13,\n",
    "    \"lr_factor\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing (4694, 1968)\n",
      "Instantiating dataset\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mintr_cvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/scarches/models/trvae/trvae_model.py:137\u001b[0m, in \u001b[0;36mTRVAE.train\u001b[0;34m(self, n_epochs, lr, eps, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m   Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m        kwargs for the TrVAE trainer.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trVAETrainer(\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madata,\n\u001b[1;32m    135\u001b[0m     condition_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcondition_key_,\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_trained_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/scarches/trainers/trvae/trainer.py:236\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, n_epochs, lr, eps)\u001b[0m\n\u001b[1;32m    233\u001b[0m         batch_data[key] \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Loss Calculation\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Validation of Model, Monitoring, Early Stopping\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_epoch_end()\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/scarches/trainers/trvae/trainer.py:273\u001b[0m, in \u001b[0;36mTrainer.on_iteration\u001b[0;34m(self, batch_data)\u001b[0m\n\u001b[1;32m    270\u001b[0m                 module\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Calculate Loss depending on Trainer/Model\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    275\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/scarches/trainers/trvae/unsupervised.py:63\u001b[0m, in \u001b[0;36mtrVAETrainer.loss\u001b[0;34m(self, total_batch)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, total_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 63\u001b[0m     recon_loss, kl_loss, mmd_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtotal_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     loss \u001b[38;5;241m=\u001b[39m recon_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_alpha_coeff()\u001b[38;5;241m*\u001b[39mkl_loss \u001b[38;5;241m+\u001b[39m mmd_loss\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_logs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/scarches/models/trvae/trvae.py:121\u001b[0m, in \u001b[0;36mtrVAE.forward\u001b[0;34m(self, x, batch, sizefactor, labeled)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecon_loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    119\u001b[0m     x_log \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m--> 121\u001b[0m z1_mean, z1_log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_log\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m z1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling(z1_mean, z1_log_var)\n\u001b[1;32m    123\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z1, batch)\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/scarches/models/trvae/modules.py:94\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x, batch)\u001b[0m\n\u001b[1;32m     92\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, batch), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mFC \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m means \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_encoder(x)\n\u001b[1;32m     96\u001b[0m log_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_var_encoder(x)\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/scarches/models/trvae/modules.py:26\u001b[0m, in \u001b[0;36mCondLayers.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     expr, cond \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(x, [x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_cond, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_cond], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpr_L\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcond_L(cond)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/bpEXA/expiMap_hsl_project/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "\n",
    "intr_cvae.train(\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
